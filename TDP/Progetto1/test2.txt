Capitolo 1 
Introduzione
La Situation Awareness è una tematica di grande rilievo nel panorama dell’ICT attuale per quanto riguarda la progettazione di sistemi ed applicazioni intelligenti. 
La SA è materia particolarmente complessa, questo sia per una intrinseca difficoltà concettuale sia perché sono moltissime e articolate le tecniche e gli approcci proposti. In particolare gli approcci che rendono la SA efficace ed efficiente fanno uso di tecniche ibride che richiedono conoscenze multidisciplinari, uso sofisticato di modelli matematici e mentali, conoscenze spinte di computer science, peraltro poco codificate, ecc. Tutto ciò conferisce alla SA ancora un alone di mistero, la rende poco diffusa e poco utilizzata anche in ambienti tecnologicamente avanzati e soprattutto priva la comunità di tutto il potenziale in termini di utilità che essa può invece esprimere se utilizzata nei contesti adeguati. 
Nel presente lavoro desideriamo raccogliere nel nostro piccolo ambito, una sfida, peraltro molto sentita da studenti di ingegneria non informatici, ovvero rendere disponibile un prototipo di sistema che consenta ad un ingegnere che ha realizzato un modello di SA CST-Based di implementarlo e osservarne il funzionamento pur in assenza di particolari conoscenze ICT.
1.1 Obiettivi
Lo scopo ultimo di questo lavoro di tesi è fornire uno strumento prototipale, che possa essere utilizzato nell’ambito della configurazione di uno scenario di situation awareness e che sia in grado di provvedere alla raccolta ed all’analisi dei dati necessari, fornendo poi una presentazione adeguata all’utente dei risultati ottenuti. Nello specifico, in virtù delle funzionalità sopra descritte, gli obiettivi del mio lavoro sono stati:
	Studio della tecnica di Situation Awareness appropriata all’applicazione in esame
	Studio delle tecnologie più aderenti agli scopi applicativi del progetto
	Modellazione del sistema 
	Realizzazione e validazione di un prototipo


1.2 Aree di Studio
Per meglio comprendere la sfida celata dietro la volontà di modellare un sistema unico, semplice, intuitivo, completo e scalabile in grado di approcciare il compito di identificare una data situazione, è stato necessario innanzitutto andare alla radice del problema approfondendo le conoscenze sulle origini e lo sviluppo della Situation Awareness. Dunque è seguita a questa fase introduttiva una panoramica sugli attuali approcci al problema e lo studio, nello specifico, della Context Space Theory, scelta come mezzo per il raggiungimento dello scopo prefissato. 
A questo punto restava da stabilire una struttura interna al programma. Il paradigma di progettazione ad agenti, per la sua natura scalabile, flessibile, distribuita ed intelligente si è rivelato il più adatto. Poiché dar forma ad un sistema di questo tipo non è semplice, vista la potenziale complessità di un agente, è stato necessario analizzare le possibilità offerte da questa architettura e mediare fra un buon livello di autonomia degli agenti ed una moderata complessità realizzativa. Il sistema sviluppato sfrutta i principali punti di forza di un Sistema Multi Agente, ovvero la capacità dei singoli agenti di comunicare e collaborare, mantenendo una netta divisione dei compiti. La piattaforma utilizzata per l’implementazione di questa architettura è JIAC.
1.3 Organizzazione del Lavoro
Il lavoro ha mosso i suoi passi a partire dall’analisi delle principali tecniche di situation awareness, i cui risultati sono presentati nel primo paragrafo del secondo capitolo di quest’opera, dedicato appunto alle tematiche studiate durante il mio lavoro di tesi. Un paragrafo dello stesso capitolo è stato dedicato all’approfondimento della Context Space Theory, nel quale ne sono presentate le principali proprietà e caratteristiche. Nel terzo ed ultimo paragrafo dello stesso, invece, viene presentata l’architettura ad agenti e la piattaforma utilizzata per l’implementazione del sistema, ovvero la prima citata JIAC. 
La maggior parte del tempo impiegato nella stesura di quest’opera è stato assorbito dalla modellazione e dalla successiva implementazione del sistema, i cui passi e il cui risultato sono presentati nel terzo capitolo, nel quale viene introdotta la struttura che si è deciso di fornire al sistema con le relative motivazioni per le scelte implementative prese.  
 

Capitolo 2
Metodologie Approcci e Tecniche
In questo capitolo verrà fornita un’adeguata presentazione alle metodologie ed alle tecniche che hanno caratterizzato la progettazione del sistema prima e che ne hanno accompagnato e guidato lo sviluppo poi. Dopo una disamina delle più diffuse tecniche di identificazione e catalogazione delle situazioni, particolare attenzione verrà posta alla tecnica scelta come più adeguata ai nostri fini. In conclusione, verrà presentata l’architettura dei sistemi ad agenti, scheletro del programma realizzato.
2.1 Situation Awareness
È immediato, dalla traduzione del termine, che un sistema in grado di compiere situation awareness è quel sistema che, a partire da un certo set di informazioni, riesce ad identificare il contesto in cui si trova ad operare. La necessità di pensare ad un sistema dotato di questa capacità deriva direttamente dallo sviluppo tecnologico degli ultimi decenni e dal bisogno dell’operatore umano di riuscire a star dietro alla crescente quantità di informazioni che ne è derivata. Infatti, per quanto le possibilità che la tecnologia offre all’uomo aumentino giorno dopo giorno, le capacità cognitive di quest’ultimo rimangono le stesse, la mole di dati con cui il nostro cervello viene bombardato, dunque, non sempre trova un meccanismo efficiente che le traduca in informazioni. Storicamente, questo problema emerse con la nascita e lo sviluppo dell’aviazione, quando la plancia dei velivoli arrivò ad un punto tale di saturazione, per via dell’eccesso di strumentazione, da non essere più facilmente interpretabile dal pilota. Si definì quel modo di progettare sistemi “tecnocentrico” ed iniziò allora la ricerca di un paradigma di progettazione che ponesse invece l’uomo al centro dei suoi sforzi, seppure il problema da superare fosse proprio capire come riuscire in questo intento. 
Dunque come risolvere il problema? Non è stato semplice dare una risposta a questa domanda che, per quanto possa sembrare banale, nasconde in realtà molte insidie. In primo luogo si è osservato che, nello sviluppo delle prime interfacce uomo macchina nelle quali erano coinvolti sistemi complessi, non tutte le informazioni che venivano presentate erano poi effettivamente utili ai fini del processo decisionale dell’operatore. 
A discapito dell’apparenza, la progettazione di sistemi in grado di operare al posto dell’uomo, o di prendere decisioni in sua vece, o di filtrare autonomamente le informazioni ritenute inutili per l’operatore, non sortirebbero l’effetto desiderato. Innanzitutto perché il criterio fondamentale di questa filosofia di pensiero è che l’operatore deve essere sempre e costantemente informato di ciò che avviene nel sistema e questo non può accadere se è il sistema stesso a filtrare le informazioni. C’è poi da considerare il fatto che, dovendo essere l’uomo a governare il processo, se questo non è in grado di tenere traccia delle operazioni svolte dal sistema, non sarà poi in grado di entrare nel processo operativo e prendere decisioni “consapevoli”. La soluzione a questi problemi risiede proprio nella Situation Awareness. Un sistema in grado di riconoscere il contesto in cui opera può presentare in maniera efficiente e puntuale le informazioni all’utente, in base agli obbiettivi da perseguire in quella specifica situazione. 
Un sistema orientato alla situation awareness è innanzitutto orientato alla raccolta di informazioni utili per l’utente, visto che la chiave per il riconoscimento delle situazioni è un apparato informativo il quanto più completo e pertinente possibile. Per finire, come detto in precedenza, un sistema di questo tipo ha come obiettivo fondamentale quello di tenere l’utente sempre informato sull’avanzamento del processo monitorato, delle operazioni svolte o di qualsiasi cosa il sistema si occupi.
La Situation Awareness può essere scomposta su tre differenti livelli:
	Acquisizione dei dati sull’ambiente
	Riconoscimento della situazione corrente
	Proiezione degli stati futuri 

Proprio l’acquisizione dei dati inerenti ambiente circostante è la base di tutto il processo che porterà poi all’identificazione del contesto, è quindi evidente l’importanza di questo primo passaggio. Le difficoltà intrinseche a questo stadio sono notevoli, sia dal punto di vista pratico che progettuale. Partendo proprio da quest’ultimo aspetto, c’è bisogno di una profonda conoscenza del dominio di interesse per riuscire ad identificare con efficacia ed efficienza le informazioni di cui si ha bisogno, dove con efficienza si intende la capacità di discernere fra informazioni fondamentali e quelle superflue, responsabili solo di un appesantimento del sistema. L’altro aspetto da tenere in conto è la difficoltà nel modellare questa conoscenza in maniera tale che sia trasmissibile ad un sistema.
Le statistiche affermano che in circa i tre quarti dei casi è da ricercarsi a questo livello l’origine di un fallimento nel riconoscimento di una situazione e, per quanto detto, la cosa non ci sorprende affatto vista l’impossibilità di raggiungere buoni risultati con una base di conoscenza debole.

Il secondo livello opera sui dati raccolti al fine di produrre informazioni. Mediante un processo di analisi ed aggregazione dei dati, messi poi in relazione con gli obbiettivi posti, viene effettivamente prodotta la conoscenza. Possiamo vedere quel che accade a questo stadio come una contestualizzazione delle informazioni che al passo precedente erano atomiche e prive di profondità. In questo secondo piano della piramide ed, ancor di più, in quello superiore vengono applicati meccanismi complessi ereditati proprio dal ragionamento deduttivo umano. Riconoscere una situazione vuole appunto dire riuscire ad identificare un modello noto a partire da alcuni indicatori già osservati in passato.

Nel terzo livello vengono effettuate proiezioni sul futuro basandosi sulle informazioni a disposizione. C’è bisogno di una grande conoscenza intrinseca del dominio in cui si va ad operare e si deve inoltre disporre di solide basi di conoscenza derivate dal secondo livello di SA. Avvalendoci di un’analogia con il processo cognitivo umano, mentre il livello precedente poteva essere raggiunto da qualsiasi soggetto dotato di un’adeguata istruzione sul dominio di interesse, la capacità di intravedere possibili scenari futuri a partire dalle informazioni in possesso sul presente deriva esclusivamente dall’esperienza. 
Sottolineiamo ancora una volta che il processo appena descritto è piramidale, ovvero il livello successivo opera a partire dai risultati conseguiti dal livello sottostante. Dunque, se la piramide in questione ha fondamenta deboli, le crepe strutturali si propagheranno fino in cima con risultati decisamente catastrofici. Questa può essere una prima, semplice spiegazione del grande peso che ricopre il primo livello nella statistica di fallimento che abbiamo sommariamente riportato. 
Considerando che la Situation Awareness, prima ancora di essere una prerogativa dei sistemi di elaborazione, è la chiave del decision making effettuato dagli esseri umani, d’ora in avanti procederemo alla descrizione del suo funzionamento proprio riferendoci al caso umano. 
Come accennato in precedenza, un essere umano è in grado di riconoscere una situazione per via di un meccanismo di matching tra quello che ha potuto constatare sull’ambiente circostante ed una serie di modelli presenti nella sua memoria. La raccolta delle informazioni che contribuiscono alla formazione di questa “impressione” sull’ambiente è tuttavia limitata da due fattori principali: in primo luogo, per essere in grado di notare un particolare, quanto per essere in grado di cogliere il verificarsi di un nuovo evento od il cambiamento di una circostanza nell’ambiente, è richiesta una certa attenzione. C’è tuttavia un limite ai soggetti ai quali è possibile prestare attenzione, potremmo quasi dire che questa è una risorsa preziosa e limitata. Un secondo collo di bottiglia è rappresentato dalla memoria, l’elaborazione degli input provenienti dall’ambiente avviene mediante un preventivo immagazzinamento nella memoria a breve termine, o working memory, la quale tende a saturarsi relativamente in fretta e la conoscenza al suo interno svanisce in breve tempo se non “rinfrescata”. 
Proprio i modelli mentali prima citati offrono una scappatoia da questi limiti, infatti attenzione e memoria sono maggiormente sollecitati in presenza di nuove situazioni, mentre il loro compito è decisamente più lieve quando nella nostra mente c’è già un modello della situazione che stiamo osservando. Un mental model è una struttura intellettiva complessa, che rende l’utente in grado di capire quali informazioni prediligere e quindi quali poter trascurare, rende anche capaci di effettuare proiezioni sul futuro e di creare aspettative. Meccanismi simili sono molto potenti, un ulteriore esempio è dato da quelli che sono definiti schemata e scripts. Uno schema è un mental model ancora in uno stato prototipale, quindi più generico e flessibile. Lo script è invece quello che potremmo definire un comportamento automatizzato associato ad uno schema, ovvero una serie di azioni memorizzate come ‘da applicare’ sempre al riconoscimento di un determinato schema.
Durante lo svolgimento del proprio compito, un utente può operare secondo due metodologie: può essere guidato dagli obbiettivi, approccio top-down, o dai dati, approccio bottom-up, similmente può procedere l’analisi svolta ai fini della SA. 

In un approccio top-down (goal-driven), in base ai goals che si desidera raggiungere, si focalizzano sforzi ed attenzione verso un determinato set di elementi, prediligendoli quindi rispetto ad altri. Un approccio di questo tipo è efficiente, ma limitante. Per fare un esempio, un autista di autobus ha fra i suoi goal quello di non superare il limite di velocità durante il viaggio, quindi la sua attenzione è focalizzata sulle condizioni della strada e la velocità del mezzo. Tuttavia, se egli non disponesse di una certa flessibilità, potrebbe non notare, ad esempio, un segnale di avaria al motore o un qualsiasi altro alert invece fondamentale per la sicurezza del viaggio. Il vantaggio quindi di riuscire a selezionare solo un numero limitato di fattori chiave è potenziale causa di eccessiva negligenza verso altri. 
D’altro canto un approccio bottom-up, quindi data-driven, che seleziona i goal in base alle informazioni a disposizione, è decisamente più esoso dal punto di vista delle risorse, perché costringe a mantenere l’attenzione su tutti i parametri di interesse, senza alcun meccanismo di predilezione, come invece avveniva nel caso precedente.   
Dunque non esiste un approccio migliore di un altro, ma la chiave per conseguire la maggiore efficienza possibile risiede nella flessibilità, riuscire a cambiare la propria visione delle cose nel minor tempo possibile e, soprattutto, quando è più necessario è una key feauture nel conseguimento della SA.

2.1.1 Panoramica sulle tecniche SA
Sono tre le principali problematiche attorno alle quali si concentra la ricerca al fine di potenziare il meccanismo di identificazione delle situazioni nel pervasive computing, ovvero la loro rappresentazione, la loro specifica e come poi ragionare su di esse. Oltre a questo, la varietà dei campi di applicazione della Situation Awareness complica ulteriormente le cose, infatti “uno dei principali requisiti di un pervasive computing system è di offrire il servizio corretto, al corretto utente, nel giusto posto ed al giusto momento, nel modo migliore” [1]. 
È possibile dividere in due grandi categorie le tecniche utilizzate per lo studio delle situazioni nel Pervasive Computing, ovvero tecniche Specification Based e Logic Based.
Approcci Specification Based
La modellazione del processo di riconoscimento, a partire dalla descrizione e formalizzazione della conoscenza sul dominio di interesse fino ad arrivare alla descrizione e formalizzazione dei meccanismi di reasoning necessari, avviene ad opera di esperti. È applicabile fondamentalmente a quegli scenari in cui esiste un rapporto diretto e facilmente identificabile fra le situazioni ed un “ridotto” numero di sensori.  Dunque fra gli indubbi vantaggi possiamo di sicuro annoverare la facilità di progettazione di un sistema simile. Inoltre si fa comunemente uso di ontologie per la descrizione e l’elaborazione delle informazioni e nello sviluppo delle deduzioni logiche sul contesto e le situazioni.  Questo approccio dimostra i suoi limiti in quei campi in cui è richiesto di dialogare con un grande numero di sensori e di fronte alla necessità, presente e viva in alcuni sistemi, di gestire i gradi di incertezza provenienti dai sensori. 
Un esempio di questo approccio è la Programmazione Logica (Logic Programming). L’obbiettivo di questa tecnica è fornire una base teorica per la costruzione di sistemi situtation-aware con le capacità di rappresentare formalmente la specificazione logica di una situazione, verificarne l’integrità e la consistenza ed estendere gli attuali sistemi al fine di renderli in grado di gestire una maggior quantità di dati provenienti dai sensori e, quindi, riconoscere un maggior numero di situazioni. [2]. La discretizzazione della conoscenza proviene esclusivamente dal lavoro degli esperti e si parte sempre dall’astrazione dei dati dei sensori appartenenti allo specifico dominio di applicazione. 
Un approccio mutuato dal campo dell’Intelligenza Artificiale è la Logica Spaziale e Temporale, che si basa su una semplice assunzione, ovvero è impossibile identificare una situazione specifica a partire da dati puri senza possedere, almeno, le informazioni di contesto di base, quindi: dove e quando. L’utilizzo di tecniche in grado di tenere in considerazione fattori spaziali e temporali permette la definizione di vincoli più efficaci nell’identificazione di relazioni esistenti fra diverse situazioni, come composizione ed esclusione mutua [3].
Presentiamo ora uno degli strumenti più potenti in questo ambito, ma comunemente utilizzato anche in molti altri, ovvero le Ontologie. Un’ontologia può essere definita come una rappresentazione formale, condivisa ed esplicita di una concettualizzazione di un dominio di interesse. Rappresentano uno strumento estremamente potente, e quindi largamente utilizzato in più ambiti, perché in grado di modellare una grande varietà di concetti in maniera formale ed intellegibile non solo da sistemi informatici, ma anche da umani [4]. Nel campo della SA sono proprio le situazioni, i sensori ed i meccanismi logici che legano questi due livelli della conoscenza ad essere modellati mediante l’uso di ontologie. 
Un enorme vantaggio offerto dalle ontologie è la possibilità di rilevare inconsistenze nella base della conoscenza ed, inoltre, di derivare nuovo sapere tramite l’elaborazione delle informazioni a disposizione [5]. Dunque c’è da sottolineare che, anche se esistono e sono già stati formalizzati e verificati svariati meccanismi di reasoning in grado di operare sulle ontologie, la più grande difficoltà nell’adozione di questo approccio è la quantità di lavoro necessaria per modellare nel corretto modo la conoscenza nel dominio di interesse, per quanto le regole per farlo siano chiare e ben definite. 
Come vedremo in seguito, la possibilità offerta dall’uso di ontologie di modellare la conoscenza in maniera assolutamente non ambigua, rende queste tecniche adatte anche all’uso nel campo dei sistemi ad agenti. 
La Logica Fuzzy, che ritroveremo anche più avanti in questa trattazione come mezzo di espansione di un’altra importante teoria nel campo SA, definisce un nuovo concetto di appartenenza per un dato ad un certo insieme, ovvero si passa da un concetto netto di appartenenza, si/no, ad uno mediato da un certo grado di incertezza derivato da una funzione di membership definita sull’insieme. 
Nel pervasive computing la logica Fuzzy è utilizzata per tradurre in linguaggio naturale il prodotto dei sensori, questo perché spesso è proprio con variabili linguistiche che si dà una definizione delle situazioni e dunque è utile disporre di un meccanismo chiaro e ben definito che renda possibile un dialogo fra questi due “mondi”.
Ha guadagnato una notevole attenzione nell’ultimo periodo la Teoria dell’Evidenza, formulata da Dempster negli anni ’60 e poi successivamente arricchita da Shafer, ponendosi come alternativa agli approcci puramente probabilistici. Si basa su tre concetti fondamentali: funzione di credenza, struttura di discernimento e regole di combinazione.  Il concetto fondamentale che sta alla base di questa teoria è che le prove, appunto le evidenze, spesso influenzano non solo una singola ipotesi, in questo caso la determinazione di una singola situazione, ma un intero sottogruppo di queste. Dunque propagando sia le informazioni che le incertezze derivanti dai sensori si può arrivare ad escludere di volta in volta i sottogruppi non realmente di interesse, fino ad arrivare ad una deduzione finale, nella quale sarà comunque riportata la mancanza di informazioni propagata dall’inizio della catena deduttiva, così da avere anche un grado di precisione per il risultato raggiunto. Nel campo della Situation Awareness, i dati dei sensori vengono presi come evidenze per ipotesi di alto livello, questi vengono poi combinati per ottenere un grado di conoscenza per ipotesi di livello più alto, finché non viene determinato il grado di conoscenza dell’attività di interesse. 
Approcci Logic Based
In questo caso si deducono i modelli che descrivono una situazione a partire dallo studio di un set di dati raccolti sul campo ma, una sostanziale e decisiva differenza con la tipologia di approcci prima descritti è che si adempie a tale compito tramite l’ausilio di meccanismi e teoremi presi in prestito dal mondo dell’Intelligenza artificiale e del Machine Learning, seppure con la supervisione di esperti. Il grande vantaggio è proprio la possibilità di usare meccanismi automatizzati per l’identificazione degli schemi associabili ad una situazione, ma, come anticipato, di contro questo richiede la presenza di un ricco set di dati preesistenti che serviranno per il training del sistema. In questa macro-famiglia di processi ne possiamo trovare un gran numero ad approccio probabilistico derivati dalla teoria Bayssiana.
Il primo che andiamo a presentare è proprio il naïve Bayes, basato sul teorema di Bayes della probabilità a posteriori: 
P(H¦X)=(P(X¦H)P(H))/P(X) 
Dove X è la prova a supporto dell’ipotesi H, P(X) e P(H) sono le probabilità a priori di X ed H e P(X|H) è la probabilità a posteriori condizionata di X dato H. 
Non si fa altro che classificare le ipotesi sulla base della stretta indipendenza delle evidenze le une dalle altre, l’assunzione di questa condizione permette di ridurre drasticamente il costo computazionale di questo metodo, ma ne rappresenta anche il più grande limite. Questo approccio risulta applicabile quando non c’è un grado di incertezza sulle misurazioni, in questo caso esso dimostra anche ottime prestazioni.
Qualora l’ipotesi di indipendenza non fosse sostenibile, si fa ricorso ad una Bayssian Network. In questo caso viene costruita una rete, ovvero un grafico orientato, in cui ogni nodo, simbolicamente una variabile aleatoria, è collegato da un arco che indica un legame causale fra i due. I nodi radice sono dotati di una funzione di probabilità a priori, mentre i nodi intermedi ed i nodi foglia di probabilità condizionate. Si può dunque facilmente notare che il naïve Bayssian model rappresenta un caso particolare della rete Bayssiana in cui un nodo radice è direttamente collegato ad un nodo foglia.
Un altro modello che è stato, ed è tutt’ora, ampiamente utilizzato è l’Hidden Markov Model (HMM) [6]. Una catena di Markov è un particolare tipo di processo stocastico, utilizzato in questo caso per descrivere un sistema in cui la transizione fra uno stato ed un altro può essere rappresentata come una sequenza in cui la probabilità di transizione da uno stato al successivo dipende solo da quello immediatamente precedente. Allora in questo senso un HMM non fa altro che identificare, in un set di eventi, quello che con maggiore probabilità porta al riconoscimento di una data situazione. Anche in questo caso, però, vige la limitazione della stretta indipendenza fra gli eventi. 
Per costruzione, quindi, l’Hidden Markov Model non è in grado di identificare la dipendenza fra eventi nel lungo termine, né tantomeno relazioni complesse fra eventi. Al contrario, invece, nel Conditional Random Fields (CRF) l’ipotesi di indipendenza degli eventi viene superata prendendo in considerazione la probabilità condizionata dell’intera sequenza di stati, piuttosto che la probabilità congiunta dei singoli [7]. Un’estensione di questa tecnica è rappresentata dalla Context-free Grammar (CfG), in questo caso il campo di applicazione primario è la modellazione di processi ben strutturati, in cui le regole di aggregazione delle singole azioni per formare azioni complesse sono chiare e possono essere esplicitate formalmente. Applicando ricorsivamente le regole prima descritte è possibile, a partire dalle azioni più complesse, arrivare alle azioni atomiche per scomposizione [8]. La CRF ed anche questa sua estensione, la CfG, dimostrano i loro limiti in presenza di processi complessi, nei quali esistono vincoli temporali e spaziali più stringenti fra i soggetti coinvolti, questo perché diventa complicato definire le regole di produzione delle azioni.
Cambiando approccio al problema, presentiamo i Decision Trees, i quali si configurano come uno strumento per l’identificazione di regole di classificazione, il cui grande pregio è quello di essere facilmente intellegibili anche dall’uomo. Scendendo giusto un po’ più nel dettaglio, come fa intuire il nome, questo modello si basa su una rappresentazione ad albero, dove una foglia indica una classificazione e gli archi che connettono i vari nodi rappresentano la relazione fra le caratteristiche, che portano all’identificazione della classificazione. Questo metodo si dimostra decisamente molto efficace, a patto che il data set da analizzare non sia eccessivamente corposo, in questo caso le risorse fisiche richieste per l’elaborazione diventano eccessive.
Nel caso in cui si disponga di un data set molto ricco, contenente informazioni precise sull’ambiente da analizzare, un’ottima risorsa da tenere sicuramente in considerazione è rappresentata dalle Reti Neurali Artificiali. Queste possono automaticamente imparare e generare schemi complessi per la rappresentazione e l’analisi del contesto in questione. Una rete neurale è composta da neuroni artificiali interconnessi fra di loro ed organizzati in una architettura multi livello. Questi neuroni ricevono dati da un layer esterno di input, le elaborano e le trasmettono ad i neuroni ai quali sono interconnessi fino ad arrivare alla produzione dell’informazione, che viene poi comunicata mediante un layer di output. Grazie alle reti neurali è possibile estrarre un modello inerente ad un dominio poco conosciuto, a patto che su di esso siano disponibili sufficienti training data [9], nel caso in cui questi fossero incompleti od imprecisi le prestazioni del sistema ne verrebbero fortemente compromesse.
Dunque è evidente che in questa famiglia di approcci all’SA ed al Pervasive Computing, i Training Data si configurano come una risorsa fondamentale, riuscire a costruire un data set ricco e quanto più completo possibile può diventare il fattore discriminante per il corretto funzionamento del sistema. Di conseguenza sono nate ricerche orientate verso nuove strade per l’acquisizione di tali dati, una di queste è il Web Mining. Alla base c’è un’idea semplice quanto geniale: il web è indubbiamente una risorsa fondamentale per il knowledge moderno, grazie ad i motori di ricerca chiunque può acquisire conoscenza su materie prima sconosciute, avvalendosi dei numerosi “how to” presenti in rete, dunque si è pensato che gli oggetti fondamentali per svolgere un’attività, a prescindere dalla specifica sequenza di azioni o dalla metodologia applicata, siano gli stessi. È stato possibile dimostrare che i termini ricorrenti nelle guide on line per svolgere una determinata attività erano anche quelli più rilevanti nell’identificazione dell’attività stessa. Dunque, a patto che le attività di interesse non abbiano strumenti in comune, il web mining ha dimostrato di rispondere alla necessità di popolare i data set necessari alle elaborazioni in questi ambiti. 

2.2 Context Space Theory
Nella Context Space Theory (CST) le informazioni riguardanti il contesto vengono viste sotto forma di vettori in uno spazio multidimensionale. La Situation Awareness implementata mediante tecniche CST lavora tramite "confidence level", risultando così più flessibile nell'applicazione a casi reali. Essa è in grado anche di comprendere e lavorare fornendo diverso peso alle caratteristiche di contesto per ogni scenario, riuscendo così a discernere quelle utili da quelle che non danno contributo significativo in relazione al caso in questione.
A differenza degli approcci Bayssiani, nei quali una data situazione può verificarsi o meno e se ne calcolano le probabilità, nella CST la situazione ha diversi gradi di occorrenza. Possiamo dire, in parole povere, che mentre l'approccio statistico è più drastico nel discernere le situazioni, con la CST vengono individuate varie “sfumature di grigio" nel mezzo, questo si traduce nella possibilità da parte di un sistema così progettato, di identificare potenzialmente una situazione, con un certo coefficiente compreso fra zero e uno, considerando così anche un margine di errore.
I parametri di interesse per un dato contesto vengono chiamati context attribute. Questi possono essere già definiti, ricavati direttamente da sensori o ottenuti mediante elaborazione dei dati ricevuti da questi. La caratteristica della Context Space Theory è che ogni context attribute può essere visto come un asse, l'insieme di tutti questi assi forma il context space (o application space). Un set di context attribute value (i valori assunti dai context attributes in un dato istante) prende il nome di context state, che quindi nel nostro caso si configura come un punto nello spazio vettoriale prima definito. Questi punti hanno di solito un margine di imprecisione dovuto proprio alla natura delle osservazioni dei sensori, le quali hanno a loro volta gradi di imprecisione.
Il processo di elaborazione riceve in ingresso il context state e restituisce come output un confidence level, ovvero un valore compreso fra zero ed uno che può essere visto come una misura della sicurezza con la quale si è identificata una certa situazione. 
Il confidence level può essere calcolato come segue:
 conf_S (X)= ?_{i=1}^N¦?w_i*contr_(s,i) (x_i ) ?
Formula 1
confs(X) è il confidence level per la situazione S del context state X, mentre gli elementi Xi  rappresentano un particolare context attribute, pesato mediante il coefficiente Wi (la somma di tutti i pesi è unitaria). L'ultimo elemento al secondo membro indica il contributo al confidence level del singolo context attribute. La funzione che si occupa di restituire il confidence level è normalmente una step function che può essere espressa come segue:
 
Formula 2
Dove si fa corrispondere al contribution value un valore ‘a’ in base all'intervallo in cui questo è compreso. Gli intervalli devono essere tra di loro separati e l’insieme di tutti gli intervalli deve coprire tutto il range di valori che può assumere l’i-esimo context attribute. Gli elementi ai (contribution level) hanno valori in [0,1], tuttavia questi possono anche essere settati ad UD (undefined), questo di solito corrisponde ad un context state mancante. 
Nel caso in cui si desideri o preferisca lavorare su valori booleani, si utilizza una soglia da applicare al confidence level, come di seguito:
 
Formula 3
in questo caso allora, se ci sono confidence level indefiniti per una situazione, questa viene segnalata come non occorsa, oppure la computazione non dà esito alcuno.
I pesi, i contributi al confidence level e le soglie possono essere definiti manualmente da un operatore, esistono tuttavia anche delle tecniche automatiche per fare ciò:
	Definire i vincoli: per alcuni campi di applicazione è nota l’occorrenza o meno di una situazione in presenza di un fissato context state. Dunque i parametri di interesse possono essere stabiliti a partire da test sul campo o da studi sull’area di interesse
	Nel caso in cui i test di cui prima fallissero, è possibile modificare i parametri citati al fine di correggere l’errore. Ad esempio, se una situazione viene segnalata come verificata quando invece non lo è, è possibile ridurre il suo contribution level.
	Tramite l’utilizzo di labelled data (ovvero dati significativi, ottenuti dall’interpretazione dei dati grezzi riguardanti l’area di interesse), questo tipo di dato può essere ricavato tramite lo studio dell’area di interesse o tramite test effettivi sul campo
La metodologia di scelta dei parametri di interesse è un’area molto vasta e per lo più inesplorata. Possiamo dedurne quindi che sia proprio questa la più grande difficoltà nell’implementazione delle tecniche CST, ovvero la determinazione dei parametri che massimizzano l’efficacia del sistema.

Situation Algebra
Dalla CST classica abbiamo la definizione delle tre operazioni algebriche:
	AND: livello di sicurezza che tutte le situazioni si verifichino simultaneamente 
	OR: livello di sicurezza che almeno una delle situazioni si verifichi
	NOT: livello di sicurezza associato alla non occorrenza di una situazione
Definizioni algebriche più rigorose sono:
 
Formula 4
Utilizzando queste tre operazioni ricorsivamente è possibile arrivare alla definizione di operazioni più complesse. Nel caso esistessero alcuni context state per i quali i confidence level siano indefiniti, allora il confidence level derivante dall’operazione algebrica di questo context state ed un altro risulta a sua volta indefinito. 
Vantaggi di un approccio CST
	È un approccio integrato: al suo interno contiene tutti i metodi necessari per guidare il processo deduttivo, il quale a partire dai dati grezzi provenienti dai sensori, porta al riconoscimento di una data situazione.
	Gestione delle incertezze: durante l’elaborazione delle situazioni il sistema può gestire imprecisioni ed anche assenza di dati provenienti da alcuni sensori.
	Potenza rappresentativa: con la CST è possibile rappresentare in un modo unificato una grande varietà di situazioni, a prescindere dalle differenze nella loro semantica. 
	Semplicità di validazione: come visto, il sistema funziona in maniera molto chiara e facilmente intellegibile anche ad un operatore umano, così che gli esperti possano seguire e validare di persona l'intero procedimento.


Definizioni
Diamo ora alcune definizioni:
	Una generica funzione f, che prende in ingresso un context state e fornisce in uscita un confidence level, viene indicata come “situation”. 
	Se per due differenti situazioni vale che: f1(x) = f2(x), ovvero che le due situazioni producono lo stesso risultato per ogni context state x, allora si dice che le due situazioni f1 ed f2 sono due rappresentazioni diverse della stessa situazione.
	Con il termine situation spaces si indicano le situazioni che possono essere rappresentate mediante le definizioni della CST.
	Una situation si dice vuota se per ogni context state x, il suo confidence level non supera un certo valore fissato f.
Relazioni fra situazioni
È possibile identificare delle relazioni fra situazioni, le quali, come vedremo, si riveleranno molto utili per verificare la correttezza del modello utilizzato per la CST. Queste relazioni sono:
	Generalizzazione: l’occorrenza di una situazione specifica comporta necessariamente l’occorrenza della situazione più generale che la include. 
Es: “Sono a pranzo” include “ho fame”
	Composizione: alcune situazioni possono essere decomposte in sottocategorie. 
Es: “a Casa” può essere decomposta in “in Salotto”, “in Cucina” etc.
	Dipendenza: due situazioni sono dipendenti se l’occorrenza di una implica la precedente occorrenza di un'altra.
Es: “sto guidando” implica “sono in auto”
	Contraddizione: due situazioni in contraddizione non possono verificarsi allo stesso momento.
Es: “sto dormendo” non può verificarsi assieme a “sto nuotando”.
Come anticipato, queste relazioni vengono utilizzate per controllare la corretta strutturazione delle situazioni definite nel nostro context space, per fare ciò si utilizza il concetto di relazione vuota.
Tuttavia se volessimo controllare la correttezza delle nostre relazioni utilizzando solo le espressioni in formula 4, potremmo farlo solo per un singolo context state. Per risolvere questo problema si utilizza una versione arricchita della CST tramite una nuova rappresentazione del nostro spazio, ovvero la Orthotope based CST. 
Proponiamo ora un'ulteriore modalità di rappresentazione per quanto visto sopra, al fine di raggiungere una complessità computazionale minore e coprire un range di possibili situazioni ancor più vasto, introduciamo il Dense Orthotope-based Situation Space. Una situazione espressa mediante questo tipo di rappresentazione è nella forma:
 
Formula 5
In cui con hight e low con rispettivi pedici sono stati indicati gli estremi per ogni intervallo di valori.
Ogni riga di quanto sopra può essere vista come un prodotto cartesiano fra intervalli, questa altro non è che la definizione di "orthotope" (generalizzazione N-dimensionale di un rettangolo). Proprio gli orthotopes sono la base della versione migliorata della CST che stiamo per introdurre. Gli orthotopes coprono l'intero application space ed ogni context state appartiene ad (/è incluso in) un dato orthotope.
Supponendo quindi che il nostro vettore di context attributes sia composto da N elementi e che il numero di intervalli associati all'i-esimo context attribute sia ri, il numero totale di orthotopes sarà L, mentre il numero totale di intervalli coinvolti sarà R, definiti come:
L= ?_{i=1}^N¦r_i 
R= ?_{i=1}^L¦r_i 

Emptiness Check
Le relazioni fra situazioni vengono verificate mediante l'emptiness check, ovvero esprimendo la situazione tramite una relazione che non dovrebbe mai risultare vera e verificare poi che questo non accada. Utilizzando la rappresentazione delle situazioni mediante la CST classica, bisognerebbe verificare l'espressione algebrica prima creata per ogni singolo context state, mentre invece è possibile un approccio più rapido mediante l'uso della orthotopes based CST.
Per effettuare la verifica è necessario:
	Esprimere la proprietà da verificare utilizzando la situation algebra, in maniera che questa sia verificabile tramite emptiness check
	Convertire le situations coinvolte in rappresentazione othotopes based CS
	Utilizzando l'espressione in situation algebra da controllare e le situazioni convertite in orthotope al passo precedente, ricavare la orthotopes-based rappresentation per l'espressione da verificare
	applicare l'emptiness check all'orthotope-based rappresentation 

Fuzzy Situations
La logica fuzzy si occupa di mediare fra l’incertezza insita nel linguaggio naturale e la necessità che spesso si incontra di dover associare a questo una quantità più o meno precisa. In altre parole, la logica fuzzy nasce per descrivere ed operare con definizioni che apparentemente possono sembrare vaghe (es. poco, molto, abbastanza, etc.).
Un insieme fuzzy è caratterizzato dal fatto che i suoi elementi posseggono un grado di appartenenza all’insieme, compreso fra 0 ed 1, differentemente dagli insiemi tradizionali in cui il concetto di appartenenza era booleano (appartiene all'insieme: si/no). Esiste una funzione che definisce questo grado di appartenenza e questa prende il nome di membership function, a valori in zero ed uno.

La logica fuzzy è molto usata nell’ambito della situation awareness per via della sua maggiore aderenza ed applicabilità a situazioni reali. La Fuzzy Situations utilizza proprio l’approccio fuzzy per l’identificazione di una situazione, a partire da una funzione di membership associata ad un attributo. In questo caso il confidence level per una situazione è espresso dalla formula seguente:
 S(X)= ?_{i=1}^N¦?w_i*µ_i (x_i ) ?
Formula 6
A differenza della formula 1, in questo caso il contribution level è dato dalla funzione µi (xi), che è proprio la funzione di membership tramite la quale è definito il grado di appartenenza del contribution value ad uno specifico insieme fuzzy.

2.3 Sistemi ad Agenti
 Per capire a fondo le motivazioni che hanno portato alla nascita ed alla diffusione dei sistemi ad agenti è utile spendere qualche parola introduttiva al fine di dipingere il quadro all’interno del quale si pone come protagonista questa tecnologia.
Il costante sviluppo tecnologico dei nostri giorni ha portato alla diffusione di sistemi embedded con capacità computazionali decisamente sovradimensionate rispetto alle loro reali necessità, questo ha aperto la strada allo sviluppo di nuove idee per sfruttare un simile potenziale inespresso. Non è raro oggigiorno sentir parlare di elettrodomestici intelligenti, nel contesto delle smarthome, ad esempio, o di braccialetti ed orologi smart, che sono realtà già da tempo, per non parlare di occhiali per la realtà aumentata e la realtà virtuale, in prossimo arrivo sul mercato consumer. Tutti questi oggetti sono virtualmente in grado di interagire, o meglio di comunicare, fra di loro. Ecco che, per sfruttare al meglio questi dispositivi intelligenti, nascono architetture come quella ad agenti. 
Ci troviamo, nello specifico, nel campo dell’Ubiquitus Computing, in cui l’elaborazione delle informazioni è affidata ad oggetti di uso comune ed ampiamente diffusi nella vita di ognuno. Al fine di garantire la migliore interazione possibile tra gli oggetti prima citati, è necessario che questi dispongano di meccanismi autonomi per svolgere il loro compito, ma anche della capacità di comunicare fra di loro per svolgerlo al meglio. Proprio la comunicazione è il fattore discriminante in questo tipo di sistemi, perché li rende capaci di eseguire compiti complessi in autonomia, essendo questi in grado di raggiungere le risorse di cui hanno bisogno. Eppure, qualora fosse necessario, l’interazione può anche essere uno strumento per delegare parte del lavoro ad altri sistemi. Quest’ultima feature è fondamentale nello scenario che stiamo andando via via a delineare. Per avere un’idea più chiara di ciò ribadiamo il nostro scopo, ovvero sfruttare la capacità computazionale degli elementi intelligenti che popolano la nostra quotidianità, e per fare ciò è impensabile programmare un unico sistema in grado di gestire ogni singolo oggetto. Ciò che è auspicabile fare è programmare ogni singolo oggetto per svolgere compiti al posto nostro, o di altri oggetti, per mezzo di un meccanismo di delegazione che sia il quanto più affidabile possibile. Ovvero, questi sistemi devono essere in grado di prendere decisioni in base alle conoscenze sul problema e sull’ambiente in cui operano e di agire per il meglio. Proprio questa può essere considerata una prima definizione di agente.
Già da questa breve introduzione è possibile intravedere la vastità del campo in cui un sistema ad agenti si pone. Infatti per la natura ed il numero dei dispositivi con i quali si vuole operare, è necessario che un sistema del genere integri e tenga conto di tutte le tecniche di programmazione per sistemi distribuiti e concorrenti, pur senza appartenere propriamente a questa branca dell’informatica. In aggiunta a questo, per quanto detto sulla necessità di un agente di operare per il meglio reagendo agli input provenienti dall’esterno, si può identificare un comportamento “intelligente” dell’agente, che deve essere in grado quindi di ragionare e vagliare ipotesi e di svolgere tutte quelle azioni e possedere tutte quelle capacità che sono proprie dell’uomo. Dunque, ecco che la nostra analisi inizia anche a coinvolgere campi tipici dello studio sull’Intelligenza Artificiale, per quanto poi nelle implementazioni pratiche non sia sempre necessario andare ad operare con sistemi così complessi, come vedremo nel seguito di questa trattazione. 
Dunque per quanto detto è facile dedurre che un sistema ad agenti è un sistema distribuito e per capire meglio come un agente opera può essere utile effettuare un parallelismo con il paradigma di programmazione ad oggetti. È possibile infatti identificare delle similitudini fra gli oggetti e gli agenti.
Agenti
Per quanto detto, dunque, un agente opera in un certo ambiente ed il suo scopo è quello di effettuare cambiamenti al suo interno. Per fare ciò egli dispone di un set di azioni, che per l’analogia con la programmazione ad oggetti prima introdotta potremmo vedere come l’equivalente dei metodi. La grande differenza, tuttavia, fra agenti ed oggetti è che un agente è dotato di una certa facoltà intellettiva, che gli consente di discernere lo stato in cui l’ambiente si trova ed eseguire le azioni più indicate basandosi, appunto, su questo stato ed in relazione agli obbiettivi da conseguire. Dunque non tutte le azioni possono essere applicate indiscriminatamente, queste devono essere adeguate allo stato dell’ambiente, ovvero devono essere presenti dei prerequisiti che ne consentano l’applicazione.
Nonostante siano disponibili più definizioni di agenti, alcune anche molto diverse tra loro data la vastità dei campi in cui è possibile applicare la tecnologia ad agenti e, di conseguenza, le diversità nelle caratteristiche che un agente deve avere in relazione al suo sistema, riportiamo quella che ne danno Wooldridge e Jennings (1995):
“Un agente è un sistema situato in un certo ambiente, capace di azioni autonome e flessibili al fine di raggiungere i propri obbiettivi”

In figura 2.3.1 è data una rappresentazione immediata del funzionamento di un agente. Le informazioni sullo stato vengono acquisite mediante sensori, siano essi fisici o logici, mentre i cambiamenti sull’ambiente vengono effettuati tramite attuatori.
Nelle applicazioni reali, l’ambiente non può essere considerato deterministico, ovvero c’è da tenere in conto la possibilità che il suo stato possa cambiare anche in assenza di stimoli da parte dell’agente, oppure, ad esempio, l’ambiente potrebbe reagire diversamente all’esecuzione della stessa azione in due momenti diversi, seppure agli occhi dell’agente lo stato del sistema in entrambi i momenti possa sembrare del tutto simile. Questo comporta naturalmente delle difficoltà, le quali, in alcuni casi, possono portare l’agente a fallire il suo obbiettivo. È fondamentale che gli agenti siano quindi preparati a questa eventualità, devono essere in grado di reagire ad un fallimento. 
Per ricapitolare quanto detto finora riportiamo due definizioni di agente, più specifiche e rigorose della precedente, dateci sempre da Woolbridge e Jennings. La prima definizione, detta debole, ci dice che un agente è un sistema software dotato di:
	Autonomia: ovvero è libero di definire i suoi obbiettivi e la strada da percorrere per raggiungerli
	Abilità Sociali: con le quali si intende la capacità di un agente di comunicare con gli altri e con l’uomo al fine di cooperare per il raggiungimento dei propri obbiettivi 
	Reattività: capacità di percepire cambiamenti nell’ambiente ed adattarsi
	Proattività: un agente può prendere l’iniziativa e creare le opportunità per raggiungere i suoi obbiettivi
Per quanto riguarda la seconda definizione, detta forte, possiamo notare dei comportamenti che siamo soliti attribuire agli umani, dunque questa è una definizione di agente più “avanzata”. Un agente, secondo la definizione forte, è un sistema dotato di:
	Mobilità: può muoversi attraverso la rete al fine di raggiungere le risorse di cui ha bisogno
	Apprendimento
	Adattamento
	Sincerità
	Benevolenza: che è la proprietà di un agente di non avere obbiettivi in contrasto con quelli degli altri agenti
	Razionalità

Per quanto riguarda poi l’aspetto più pratico, è possibile dividere in quattro macro-categorie le implementazioni più comuni del concetto di agente:
	Agente Reattivo Semplice: il quale decide quali azioni eseguire in base a semplici regole condizione-azione
	Agente Reattivo Basato su Modello: a differenza del precedente, questo agente conserva informazioni sulle azioni svolte nel passato e sullo stato del mondo, ne possiede inoltre un modello che ne descrive il funzionamento
	Agente Basato Sull’Obbiettivo: analizzando i possibili casi che si verranno a creare nell’ambiente in conseguenza delle sue azioni, il sistema sceglie quali strade intraprendere per raggiungere il suo scopo
	Agente Basato Sull’Utilità: l’agente possiede una funzione di utilità, la quale rappresenta, in un certo qual modo, una misura di quanto “buono” sia lo stato in cui l’agente si trova. L’agente sceglie l’azione che massimizza l’utilità attesa.

Ambiente
Abbiamo già detto che l’ambiente è il contesto in cui un agente opera, è quindi la fonte delle sue informazioni ed il fine del suo operato. Da ciò è facile evincere che è impossibile progettare, od anche solo pensare, un agente senza prima un’attenta analisi dell’ambiente in cui andrà ad operare.
Russel e Norvign propongono la seguente classificazione delle proprietà di un ambiente [Russe and Norving, 1995]:
	Accessibile: un ambiente si definisce accessibile se un agente è in grado di ottenere tutte le informazioni sul suo stato di cui ha bisogno e che queste siano aggiornate ed accurate.
	Deterministico: in un ambiente di questo tipo ogni azione ha uno ed un solo effetto e questo è assicurato, ovvero non c’è alcuna possibilità che l’esecuzione della stessa porti ad un risultato inaspettato.
	Statico: in un ambiente statico, lo stato non cambia se non al verificarsi dell’intervento dell’agente. Se così non fosse, ovvero se lo stato dell’ambiente potesse cambiare indipendentemente dall’operato dell’agente, questo si definirebbe dinamico.
	Discreto: un ambiente si dice discreto se al suo interno esistono un numero finito di azioni e “percetti”, ovvero di ciò che può essere misurato e percepito dall’agente. 
Purtroppo, le condizioni reali di applicazioni sono quasi sempre le peggiori possibili, in cui si ha a che fare con ambienti inaccessibili, continui, non deterministici e dinamici. Ambienti con queste caratteristiche sono definiti aperti [Hewitt, 1986]. È importante valutare anche il tipo di interazione che l’agente ha con l’ambiente, oltre alle sue proprietà. Ad esempio, esistono casi di applicazione in cui c’è la necessità che l’agente fornisca una risposta ad uno stimolo dell’ambiente in un tempo finito ed esatto, oppure che riesca a reagire in real-time, ovvero nel tempo minore possibile. Naturalmente queste specifiche sui tempi e le modalità di reazione aggiungono maggiori difficoltà alla progettazione dell’agente.

2.3.1 Architettura ad Agenti
Prima di fornire una rapida panoramica delle principali architetture disponibili per i sistemi ad agenti, è nostra intenzione soffermarci su una breve definizione che è possibile dare per chiarire cosa si intende con “architettura” di un agente. In realtà, più che una vera e propria definizione, non è altro che una banale scomposizione della struttura di un agente, facilmente deducibile proprio dalla sua descrizione più semplice. L’’architettura di un agente altro non è se non la mappa di ciò che è possibile trovare al suo interno, a partire dalle strutture dati, fino ad arrivare alle operazioni elementari che è in grado di eseguire. Il funzionamento del più semplice agente che possiamo immaginare può essere completamente descritto da due sole funzioni: see ed action (Figura 2.3.2)[10]. See è la funzione che associa un percetto ad uno stato dell’ambiente, mentre action è la funzione che associa ad uno stato dell’ambiente un’azione da eseguire. Questa definizione ci aiuta a spiegare alcuni aspetti del funzionamento degli agenti. Ad esempio, possiamo dire che un agente non conosce direttamente lo stato dell’ambiente, ma la sua conoscenza è derivata dal percetto associato ad uno stato. Per quanto la cosa possa sembrare equivalente, non lo è, poiché non è detto che ad ogni percetto possa essere associato uno ed un solo stato dell’ambiente. 
Un’aggiunta non da poco, in grado di arricchire la struttura dell’agente elementare presentato come esempio, è la capacità dell’agente di avere una memoria storica del suo operato. Ai fini pratici questo vuol dire fornire all’agente la capacità di immagazzinare gli stati precedenti ed una funzione, che chiameremo next, in grado di aggiornare lo stato corrente a partire dai percetti sull’ambiente (figura 2.3.3). La funzione action varia di poco, dato che questa non opererà più a partire dai percetti ma a partire dallo stato prodotto dalla funzione next. Questo leggero passo avanti, di per se, potrebbe non rappresentare un gran cambiamento nel funzionamento generale dell’agente, ma si pone come una base importate nell’arricchimento del modello, perché può essere interpretato come il primo passo per dotare l’agente di una sorta di “conoscenza” sul mondo esterno. Esso, infatti, diventa in grado di operare tenendo presente il passato ed orientandosi verso il futuro, conoscendo i possibili stati in cui l’ambiente può evolvere e le azioni già associate a stati noti. 

È possibile identificare quattro grandi categorie di architetture ad agenti, elencate qui di seguito con una sintetica panoramica circa i rispettivi pro e contro:
	Architetture Logic-Based: l’ambiente è rappresentato in maniera simbolica e manipolato mediante meccanismi di reasoning.
Pro: La conoscenza è per sua natura simbolica, quindi è facile da codificare in questo contesto.
Contro: è difficile rappresentare il mondo in un modello simbolico accurato.

	Architetture Reattive: in questo caso il funzionamento intrinseco dell’agente è molto più semplice di quello presentato precedentemente, in sintesi, ad ogni situazione proveniente dall’esterno corrisponde un’azione prestabilita ed il sistema non possiede nessun modello che descriva l’ambiente, dunque non implementa nessun meccanismo di reasoning.
Pro: è facile da progettare e molto efficace in ambienti dinamici.
Contro: non conoscendo il modello, sono possibili situazioni in cui i soli dati dei sensori potrebbero non essere sufficienti per prendere una decisione. In un agente di questo tipo è inoltre difficile implementare un meccanismo di apprendimento.

	Architetture BDI (Beliefe – Desire - Intention): In questa architettura l’agente è dotato di tre attitudini mentali: Beliefe, Desire ed Intention appunto, che rappresentano rispettivamente: lo stato dell’ambiente, lo stato motivazionale e lo stato deliberativo. Questi tre elementi caratterizzano l’operato del sistema determinandone il comportamento e, come è lecito aspettarsi, ne influenzano le prestazioni. Questo è il tipo di architettura più diffusa.
Pro: approccio human-centric, quindi molto facile da comprendere, ed in più è stata già pienamente formalizzata.
Contro: Non esiste un meccanismo efficiente per la sua implementazione, fattore dovuto principalmente all’inadeguatezza dei sistemi applicativi attuali.

Multi Agent System (MAS)
Un MAS è un sistema composto da più agenti, dove ognuno di questi ha come obbiettivo la cooperazione reciproca per il raggiungimento di uno scopo. 
Per quanto la definizione possa sembrare semplice ed addirittura quasi banale, la realizzazione di questo tipo di piattaforme offre un numero considerevole di sfide, anche solo dal punto di vista logico. Eppure sistemi distribuiti di questo tipo sono molto comuni, per non dire che rappresentano, effettivamente, la quasi totalità dei sistemi attualmente in circolazione, dunque non possiamo che affrontare e risolvere nel miglior modo possibile ogni difficoltà che si presenterà in questo campo.
Per dare una semplice panoramica delle problematiche a cui si faceva cenno, basti pensare ad un’azienda, in cui ogni dipendente può essere visto, ed a tutti gli effetti dal punto di vista logico lo è, come un agente. In ogni azienda ci sono diversi reparti, come ad esempio il reparto marketing, quello dirigenziale e quello operativo. Ogni reparto ha una su organizzazione interna, quindi non tutti i dipendenti sono legati fra di loro, ma lo saranno di sicuro quelli appartenenti ad uno stesso reparto. Ogni dipendente di un reparto fa capo ad un dipendente con responsabilità maggiori, il quale a sua volta fa capo ad una figura che supervisiona tutta l’azienda, supponiamo un dirigente della stessa. Eppure i reparti devono essere in grado di comunicare al fine di adempiere ad i propri compiti e devono poter organizzare la loro linea di azione basandosi su presupposti ed obbiettivi comuni. Ecco questo è il quadro astratto perfetto per rappresentare un sistema multi agente, in cui esistono specifici vincoli relazionali fra gli agenti, in cui esistono regole gerarchiche e strategie comuni che devono essere rispettate ed applicate e, qualora uno di questi fattori dovesse venir meno o essere inefficiente, a pagarne le conseguenze sarebbe tutto il sistema. 
Come più volte evidenziato, requisito fondamentale per la cooperazione è la capacità di comunicare, nei sistemi ad agenti questo avviene tramite lo scambio di messaggi. Deve dunque esistere un protocollo comune a tutti gli agenti affinché siano in grado di interpretare i messaggi scambiati, a questo fine è stato definito uno standard, il quale specifica:
	Un protocollo 
	Un linguaggio 
	Un formato per il contenuto informativo 
	Le ontologie necessarie per definire la semantica associata all’informazione (con “ontologie” si intende una rappresentazione formale, condivisa ed esplicita di una concettualizzazione del dominio di interesse)
Uno dei più diffusi linguaggi di comunicazione per gli agenti è ACL (Agent Communication Language), il quale si presenta come supporto fondamentale per la condivisione della conoscenza riguardante la semantica del contenuto del messaggio e la semantica del contesto al quale il messaggio si riferisce. 
Oltre ad un meccanismo per la comunicazione è anche necessario garantire la coordinazione degli agenti. Pensando all’esempio prima presentato dell’organizzazione di un’azienda, è facile capire perché questa è una caratteristica imprescindibile in un MAS. Innanzitutto è opinabile che un agente, con il suo operato, non influisca negativamente sull’operato di un altro. Per implementare poi le relazioni fra gli agenti, è necessario che questi riescano ad organizzarsi in maniera coerente con i propri obbiettivi. La coordinazione permette poi la condivisione di risorse e conoscenze, al fine di raggiungere maggiore efficienza nel raggiungimento degli obbiettivi comuni
Ecco alcuni approcci alla gestione della Coordinazione:
	Struttura Organizzativa: è la tecnica di organizzazione più semplice, in cui, similmente ad una architettura client server, viene offerto un framework che definisce i ruoli e le interazioni fra gli agenti. La necessità di progettare un controllore centralizzato va in contrasto con la nostra intenzione di sviluppare un’architettura decentralizzata, dunque questo non è un approccio applicabile in casi reali.
	Contrattazione: In questo caso, come auspicabile, la struttura è decentralizzata. In uno scenario di questo tipo gli agenti possono assumere due ruoli: manager e contractor. Nel momento in cui un agente non riesce a svolgere un compito affidatogli parte il meccanismo di contrattazione, entra nei panni del manager e divide il problema in più sottoproblemi, la cui soluzione viene affidata ad altri agenti, i quali assumono il ruolo di contractor. Le fasi di questo meccanismo sono le seguenti:
	Annuncio del contratto da parte dell’Agent Manager
	Presentazione delle offerte da parte degli agent Contractor
	Valutazione delle offerte e assegnazione del contratto da parte dell’Agent Manager
	Multi Agent Planning: per evitare azioni conflittuali o inconsistenti, gli agenti possono comunicare fra di loro per redigere un Multi Agent Plan, all’interno del quale saranno elencate tutte le azioni future dei singoli agenti. Questo meccanismo può essere implementato in due modi:
	Centralizzato: esiste un agente che riceve i piani di tutti gli altri e li analizza per trovare eventuali conflitti e, nel caso, cerca di modificarli per integrarli fra di loro.
	Decentralizzato: si cerca di fornire un modello dei piani degli altri agenti ad ogni singolo agente, questi poi comunicheranno fra di loro per modificare i loro piani in funzione delle informazioni ricevute 
	Negoziazione: è la tecnica più usata e prevede la comunicazione di un gruppo di agenti per il raggiungimento di un accordo comune. Può essere competitiva o cooperativa, a seconda che gli obbiettivi da raggiungere siano indipendenti o comuni.
Foundation for Intelligent Physical Agent (FIPA)
La FIPA è un’associazione internazionale il cui scopo è quello di definire standard per la tecnologia ad agenti. Innanzitutto dobbiamo approfondire meglio il concetto di MAS sotto l’aspetto implementativo. A prescindere dal tipo specifico di MAS, per tutti sarà necessaria, dal punto di vista software, l’esistenza di meccanismi per lo scambio ed il trasporto di messaggi, per la ricerca e la catalogazione dei servizi offerti dagli agenti ed inoltre di un servizio che ne garantisca l’invocazione. Mentre, dal punto di vista funzionale, c’è bisogno di tutta una serie di servizi per monitorare l’operato del sistema e gestire l’ambiente di esecuzione. Tutto questo è racchiuso in quello che va sotto il nome di MAS Platform, all’interno della quale sono contenuti gli agenti.
La mancanza di uno standard è da sempre un grande deterrente nei confronti della diffusione e dell’adozione di nuove tecnologie da parte di grandi aziende, dunque era necessario che qualcuno si facesse carico della responsabilità di regolamentare la progettazione e le caratteristiche dei sistemi ad agenti, come detto la FIPA si occupa proprio di questo, seppure non è stata l’unica ad avventurarsi in questa impresa. Proprio la FIPA ha sviluppato il linguaggio di comunicazione ACL al quale prima si è fatto cenno. L’Agent Communication Lenguage (ACL) si basa sulla Teoria Degli Atti Linguistici (Speech Act Theory) [11], secondo la quale un enunciato non serve solo ad esprimere un concetto, ma si configura come una vera e propria azione. Questo approccio è fondamentalmente la caratteristica chiave che distingue, in senso positivo, il linguaggio sviluppato dalla FIPA da quello di altre organizzazioni, come il Remote Procedure Calls (RPC) o il Remote Method Invocation (RMI) della MASIF [13]. In particolare, la nota di merito che è necessario attribuire ad ACL è la sua generalità, ovvero esso è orientato principalmente alla comunicazione in senso universale, svincolato dal contesto pratico in cui si trova ad operare.  
In figura 2.3.4 è mostrata l’organizzazione di un sistema ad agenti conforme allo standard FIPA.
 
Figura 2.3.4 [13]
Ecco nel dettaglio uno sguardo ad ogni modulo [12]:
	Agent Platform (AP): Grazie a questa piattaforma le risorse hardware disponibili vengono presentate come un’unica macchina virtuale
	Agent Management System (AMS): Offre un servizio di pagine bianche e gestisce il Life-cycle degli agenti, quindi ne permette la creazione e la gestione degli agenti
	Directory Facilitator (DF): fornisce un servizio di yellow pages, conosce indirizzo e funzionalità di tutti gli agenti.
	Agent Communication Channel (ACC): è il canale mediante il quale gli agenti comunicano utilizzando l’ACL, supporta l’interoperabilità sia all’interno che all’esterno della piattaforma
	Internal Transport Message Platform (IPMT): fornisce un sistema di inoltro dei messaggi per agenti su una particolare piattaforma, che deve essere  

2.3.2 JIAC
JIAC è un framework java based per lo sviluppo di sistemi multi agente, si concentra su requisiti industriali come sicurezza, gestione e scalabilità. L’intera piattaforma è stata sviluppata con l’obbiettivo principale di rendere quanto più facile possibile lo sviluppo di sistemi ad agenti su ampia scala, cercando di garantire scalabilità ed alte prestazioni degli stessi. Per quanto riguarda l’ibridazione con le architetture service oriented, all’interno degli agenti sono state integrate alcune caratteristiche tipiche di quella tecnologia, come un interpreter per i servizi, il quale può fornire all’agente diversi gradi di intelligenza ed autonomia, permettendo, ad esempio, l’aggregazione dei servizi o la loro ricerca semantica.
Principali obbiettivi dell’architettura JIAC:
	Distribuzione trasparente
	Interazione basata sui servizi
	Descrizione e ricerca semantica dei servizi
	Meccanismi di: Generic Security, Management e AAA (Authentication, Authorization, and
	Accounting)
	Supporto per una riconfigurazione flessibile e dinamica in ambienti distribuiti

I JIAC TNG agent utilizzano il linguaggio JADL++ (JIAC Agent Description Lenguage ++), che fornisce conoscenze basate sul linguaggio ontologico OWL (Ontology Web Language), ed un linguaggio imperativo usato per l’implementazione di piani e protocolli.
Il modello è incorporato in un framework a componenti flessibili, che supporta lo scambio delle componenti a run-time. Durante la fase di esecuzione, tutte le componenti dell’agente sono monitorate e controllate attraverso un framework di management, questo consente all’agente stesso o ad un ente esterno di verificarne in real-time le prestazioni. 
Andiamo ora a riassumere in breve l’organizzazione dell’architettura di un sistema multi agente.
Un sistema di questo tipo è composto da più Platform, ovvero macchine virtuali all’interno delle quali possono essere contenuti uno o più Agent Node, di norma ogni nodo della rete contiene una sola Platform. Un Agent Node è un contenitore di Agents, i quali svolgono le loro operazioni e mettono a disposizione i loro servizi mediante uno o più Agent Bean, che rappresentano il livello più basso dell’architettura, in cui le funzionalità vengono realmente implementate. 
 
Figura 2.3.5 [14]
L’Agent Node è una JVM che fornisce un’infrastruttura a runtime per agenti, offre il discovery dei servizi, funzioni di pagine bianche e pagine gialle e l’infrastruttura di comunicazione. Generalmente, come detto, ogni macchina fisica contiene un solo Agent Node, il quale contiene uno o più Agent che a loro volta contengono una serie di Agent Bean. Gli Agent Bean forniscono funzionalità, dette Actions, agli altri Agent.


Ogni agente JIAC contiene al suo interno i moduli seguenti:
	Matcher: effettua un confrondo fra i comandi di invoke ricevuti e l’elenco dei servizi noti, una volta trovato un insieme di servizi compatibili con l’invoke spetta all’interpreter scegliere quello più adatto, questo perché l’invoke potrebbe contenere un template per il servizio da richiamare compatibile con più servizi. 
	Memory: L’Interpreter usa la memoria dell’agente per gestire le chiamate ai servizi ed i suoi parametri. La coordinazione tra i componenti di un agente viene effettuata mediante l’utilizzo di uno spazio di tuple “Linda-like”.
	Knowledge-base: rappresenta modulo di reasoning dell’agente e può essere vista come un’area di memoria semantica.
	Interpreter: è il core dell’esecuzione del servizio.
	Adaptor: Si occupano di connettere ed interfacciare l’agente con il mondo esterno. 

 
Capitolo 3
Problematica e Metodologia Proposta
Una volta approfondite le fondamenta teoriche alla base degli obiettivi posti, presentate al capitolo precedente, è stato possibile individuare le principali difficoltà che sarebbe stato necessario superare durante lo sviluppo del sistema. Queste partono dalla modellazione in linguaggio java degli oggetti tipici della Context Space Theory, quindi degli attributi, dei context e delle situations, fino ad arrivare alla progettazione ed all’implementazione della struttura dati all’interno della quale il sistema memorizza le informazioni di configurazione per l’ambiente ed i dati derivati dai sensori. Naturalmente gran parte del lavoro di progettazione è stata dedicata agli agenti ed alla modellazione del loro comportamento e delle loro interazioni. 
3.1 Specifica dei Requisiti
Il sistema deve permettere la configurazione di un ambiente CST, quindi a partire dall’aggiunta degli attributi, si deve procedere alla definizione dei Context Spaces e, successivamente, alla definizione delle Situations. Deve essere possibile mantenere una memoria per la configurazione inserita, caricandola all’avvio del sistema, qualora ne fosse disponibile già una.
Durante l’aggiunta degli attributi, l’utente deve poter scegliere la tipologia di attributo e, ove previsto, determinare su di esso dei vincoli, dipendenti dalla natura stessa del sensore relativo a quell’attributo. A partire dagli attributi già inseriti nel sistema, deve essere possibile la definizione di Context Spaces, intesi come insieme di Context Attributes definiti sugli attributi presenti nel sistema. I Context Spaces vengono poi utilizzati come punto di partenza per l’inserimento di Situations, le quali forniscono un’associazione fra i Context Attributes del Context Space di definizione, le relative Contribution Functions ed i pesi di ognuno di questi. Per quanto riguarda le Contribution Functions, ne esistono naturalmente una grande varietà di tipologie, in questa trattazione è stata direttamente implementata la Step Contribution Function.
Quanto descritto ed ulteriori dettagli sono esplicitati nel caso d’uso in figura 3.2.1.
 
Figura 3.2.1  Caso d'uso, configurazione ambiente

Conclusasi la fase di configurazione, il sistema deve provvedere al reperimento dei dati dai sensori relativi agli attributi precedentemente definiti. Suddetti dati devono essere salvati in maniera tale che possano essere aggregati ed interpretati sotto la forma di Context State, ovvero come particolarizzazione dei valori assunti in un dato momento dagli attributi di un Context Space.
Una volta resisi disponibili i dati provenienti dai sensori, l’utente deve poter consultare il risultato delle elaborazioni su tali dati, ovvero, in relazione ad una specifica situazione, il sistema deve calcolarne il confidence level come definito dalla CST, cioè come combinazione lineare del contributo di ogni singolo attributo pesato per un determinato fattore, e presentare all’utente questi risultati, mantenendo i singoli contributi e guidando l’utente attraverso l’analisi della situazione, evidenziando quei fattori che, più di altri, hanno contribuito all’accrescimento del confidence level.
Il Data Flow Diagram in figura 3.2.2 mostra una vista di alto livello sul funzionamento complessivo del sistema.
 
Figura 3.2.2 DFD
3.2 Architettura 
Il primo ostacolo da superare durante la realizzazione del sistema ha riguardato la modellazione nel paradigma ad oggetti delle strutture dati concernenti la CST, quindi di Context Attribute, di Context Space, della Situation e delle diverse tipologie di Contribution Functions possibili. Di pari passo alla loro modellazione in java è seguita la progettazione dello schema ER delle stesse astrazioni.
Le entità caratteristiche della Context Space Theory sono state tradotte negli oggetti raffigurati nello schema in figura 3.2.1. 
Lo schema evidenzia la volontà di mantenere flessibile e, per il futuro, estensibile l’implementazione del sistema. La Step Contribution Function, effettivamente utilizzata e sviluppata, è stata considerata come estensione della classe generale Contribution Function. Possiamo ritrovare oggetti di questa famiglia al campo valore della mappa “cf” nella classe Situation.
Per quanto riguarda i context attribute, questi possono essere definiti a partire da attributi semplici oppure come composizione di più attributi per mezzo di operazioni come rapporto, somma o differenza, dunque anche in questo caso è stata implementata una classe padre ContextAttribute, estesa poi dalla classe ComplexContextAttribute, il cui campo operazione indica il tipo di rapporto che intercorre fra i due attributi coinvolti.

 
Figura 3.2.2 Class Diagram CST

Il programma è stato costruito a partire dalla progettazione dei singoli agenti per ogni macro categoria individuata nell’effettivo funzionamento. Quindi si è scelto di separare nettamente la gestione e la creazione di ogni entità, dunque è stato strutturato un Agent Manager per ognuno dei tre soggetti chiave: Context Attribute, Context Space e Situation. I tre manager comunicano ed interagiscono per condividere l’un l’altro le informazioni in loro possesso, cooperando per il corretto funzionamento del sistema. 
Per quanto riguarda la parte esecutiva, sono due i principali agenti, il Sensor Data Manager, che si occupa di avviare ed organizzare gli agenti addetti alla raccolta dei dati riguardanti gli attributi dai sensori, ed il Reasoner Agent, che opera sui dati raccolti e li elabora per produrre l’effettiva conoscenza sulla situazione. 
L’acquisizione e la presentazione delle informazioni è stata affidata ad un unico agente, l’Interface Agent, che quindi si occupa di caricare la configurazione dell’ambiente per la situation awareness, caricare i dati provenienti dai sensori virtuali, ovvero dati richiesti direttamente all’utente, durante la fase operativa del sistema e di presentare il risultato delle elaborazioni.
 
Figura 3.2.3 vista logico-concettuale
Al livello sottostante, gli agenti cooperano fra di loro per la costruzione dell’ambiente, occupandosi ognuno di un determinato elemento costituivo della teoria implementata. Il tipo di attributi che è possibile caricare dipende dagli agenti disponibili, infatti si è deciso di demandare il caricamento della configurazione degli attributi ad agenti specifici per ogni tipo di sensore, così da poter garantire scalabilità e flessibilità a seconda del dominio di applicazione. L’agente che si occupa di costruire l’interfaccia con l’utente chiede all’Attribute Manager i tipi di attributi supportati e recupera anche le informazioni sulla configurazione precedente del sistema, in particolar modo sugli attributi già configurati. La stessa richiesta viene effettuata anche al Context Space Manager, il quale provvede a caricare da database e a fornire all’agente di interfaccia la lista dei context space preesistenti. Per quanto riguarda la gestione delle situazioni, anche in questo caso si è attuato nei confronti della gestione della varietà di tipi di contribution function un meccanismo analogo a quello utilizzato per gestire la diversità nei tipi di sensori disponibili. Dunque esiste un agente specifico per il caricamento delle diverse contribution functions.
Per quanto riguarda il processo tramite il quale un utente arriva alla definizione completa di una situazione, questo è raffigurato nello schema in figura 3.2.4
 
Figura 3.2.4  Sequence diagram: configurazione ambiente
In figura 3.2.5 è fornita una vista di insieme sull’intera struttura e sulle interazioni fra gli agenti. Il meccanismo di cooperazione fra agenti per la costruzione dell’ambiente, a cui prima si è fatto accenno, basa il suo funzionamento sulla capacità di ogni agente di comunicare mediante messaggi. Nel momento in cui viene salvato un nuovo context space nel database, ad esempio, l’agente che ha effettuato il salvataggio invia all’agente responsabile dell’interfaccia un messaggio, avvertendolo dell’accaduto. L’Interface Agent, quindi, sa che la sua lista di context space non è più aggiornata e provvede a procurarsene una nuova richiedendola all’agente addetto e ad aggiornare di conseguenza l’interfaccia. Avviene pressappoco lo stesso anche all’inserimento di un nuovo attributo e di una nuova situazione. 
 
 
Figura 3.2.5 Diagramma degli Agenti 
Terminata la fase di configurazione, il sistema può essere lanciato nella seconda fase, quella operativa, in cui vengono effettivamente attivati gli agenti addetti al reperimento dei dati per ogni tipo specifico di attributo, questo compito è sotto il controllo del Sensor Data Manger Agent. Nell’ambito del mio lavoro di tesi, a titolo esemplificativo è stato incluso nel progetto un agente per la configurazione di un sensore di tipo termometro, per il quale è stata implementata un’ipotesi di interfaccia di configurazione. Oltre a questo tipo di attributo, il sistema prevede la configurazione di sensori di tipo virtuale, che come gia detto sono dati che il sistema richiede direttamente all’utente. A tal fine il Sensor Data Manager, oltre ad avere il compito di attivare gli agenti relativi a sensori fisici, interroga anche l’Interface Agent per il caricamento degli attributi virtuali e si occupa del loro immagazzinamento. 
Quando nel database si rende disponibile un set completo di rilevazioni aggregabili in un context state sul quale è definita una situazione, è possibile accedere alla terza fase, ovvero alla fruizione dei risultati relativi all’elaborazione delle informazioni riguardanti una situazione. Ancora una volta, essendo un compito di interfaccia fra l’utente ed il sistema, è l’Interface Agent ad adempiere a questa funzione, in particolare tramite l’Output Bean, il quale presenta all’utente i risultati forniti dal Reasoner Agent. Quest’ultimo, acquisiti i dati riguardanti la situazione ed il context space di interesse, costruisce una tabella in cui vengono riportati i contributi, sia individuali che pesati, per ogni singolo attributo appartenente al context. Questa tabella, restituita all’Output Bean, potrà essere presentata poi nella maniera più opportuna. Nell’implementazione in esame, questa viene fornita evidenziando i context che più hanno inciso nell’innalzamento della soglia relativa alla situazione osservata.

3.3 Il Database
Le permanenza dei dati è garantita mediante l’utilizzo di un database, sul quale vengono salvate le informazioni riguardanti la configurazione del sistema ed i dati dei sensori. Ogni agente accede alla propria porzione di database di interesse e fornisce, a chi ne fa richiesta, le informazioni in suo possesso. Quindi, per esempio, l’Attribute Manager Agent si occupa di salvare gli attributi sul database e di caricarli quando un altro agente li richiede, come è il caso dell’Interface Agent e del Context Space Agent Manager. Similmente fa quest’ultimo nella gestione dei context, così come allo stesso modo la gestione delle situazioni è demandata al Situation Manager Agent. 
Lo schema E-R del database implementato è mostrato in figura 3.3.1.
 
Figura 3.3.1 Schema Entità-Relazione

Anche in questo caso sono state utilizzate delle generalizzazioni per modellare la flessibilità di implementazione dei context attribute e delle contribution function. La tabella “Situation Attribute” è stata utilizzata per tradurre la relazione esistente fra i context attribute di una situazione, il peso e la contribution function specifica per ognuno. Infatti lo stesso attributo può essere coinvolto in più situazioni ed essere caratterizzato da una diversa funzione di contribuzione e/o un diverso peso. La funzione di contribuzione implementata, anche in questo caso, è la step contribution function. Per quanto riguarda i context attribute formati per composizione di attributi, si è fatto ricorso ad una tabella che specificasse la relazione fra gli attributi coinvolti ed il tipo di operazione. 
Per quanto riguarda il campo valore del context attribute, vista la mancanza di un campo univoco utilizzabile dovuta alla molteplicità dei tipi di attributi possibili, si è scelto di utilizzare una stringa. Nel momento in cui si va a leggere questa stringa, le si attribuisce un significato, e quindi un tipo, in base proprio al valore del campo type del context attribute. In questo modo è possibile memorizzare tutti i possibili valori, a prescindere dallo specifico attributo, particolarizzando solo il campo type e lasciando all’agente addetto all’acquisizione dei dati dal database di gestire il caso secondo l’occorrenza.
3.4 Implementazione 
Verranno presentate in questo paragrafo le interfacce mediante le quali il sistema comunica con l’utente, commentando di volta in volta il processo sottostante il livello di presentazione e già introdotto nello schema logico in figura 3.2.3. Verrà anche fornita una panoramica sui servizi offerti da ogni agente implementato nel sistema.
Interface Agent
L’Interface Agent si occupa di gestire l’interfaccia principale, la quale offre una panoramica sullo stato attuale del sistema, quindi context attributes, context spaces e situations già inserite. Rende inoltre accessibili le maschere per l’inserimento di nuovi parametri. Il sistema carica da database la configurazione attuale, così da poter sempre operare sui dati inseriti in fruizioni precedenti del programma. 
L’Interface Agent configura i servizi offerti in base agli agenti disponibili nel sistema, in particolare stiamo facendo riferimento ai tipi di attributi che è possibile caricare e, come vedremo in seguito, ai diversi tipi di contribution function disponibili. 
	Questo agente interroga un database contenente la dichiarazione degli agenti disponibili al caricamento degli attributi, con relativo tipo di attributo, quest’ultimo parametro viene presentato all’utente nello spinner visibile in figura, sotto la label “Tipo di Attributo”. In questo modo si è mantenuta fede alla volontà di rendere il programma scalabile ed estensibile, infatti se in futuro fosse necessario aggiungere nuovi tipi di attributi, basterà inserire nella configurazione del sistema il nome ed il template della action offerta dall’agente incaricato del caricamento della nuova tipologia di attributo, il quale dovrà offrire in proprio l’interfaccia per il caricamento. 
A titolo esemplificativo sono stati sviluppati due agenti responsabili della configurazione di due diversi tipi di attributo, uno specifico per un sensore fisico, in particolar modo un termometro, ed uno per la definizione di attributi virtuali, l’interfaccia di quest’ultimo è presentata nella figura 3.4.2.  
Attribute Manager Agent
I vari Agent Bean di questo agente forniscono una completa gestione di tutti gli aspetti chiave relativi a questa sezione del programma. L’Attribute Manager Bean fornisce il servizio di retrive degli agenti in grado di caricare i diversi tipi di attributo e ne comunica le specifiche all’Interface Agent, cosi che questo possa configurare la sua interfaccia. L’Attribute Loader Bean, come è facile intuire già dal nome, offre tramite la sua action la possibilità di caricare dal database gli attributi precedentemente inseriti. Tale funzionalità è richiamata sia dall’Interface Agent che dal Context Manager Agent, che utilizza gli attributi per la definizione dei Context Space.
Poiché si è voluta offrire la possibilità di definire anche vincoli sugli attributi, l’interfaccia specifica per ogni tipo di sensore è lasciata all’agente che si occupa della sua configurazione. 

Context Manager Agent
 In maniera del tutto duale a quanto visto per l’Attribute Loader Bean, stesso compito viene svolto in questo agente dal Context Loader Bean, che carica dal database i context spaces già presenti e li fornisce a chi ne richiama la action, in questo caso all’interface agent, per la presentazione all’utente, ed al Situation Manager Agent, per la definizione delle situazioni. Il Context Interface Bean, si occupa della definizione di nuovi context spaces, come mostrato in figura 3.4.3. La sua interfaccia prevedere la selezione degli attributi di interesse da una tabella, nella quale è riportato il nome ed il tipo di ogni attributo. Il campo “Tipo” è usato per selezionare la modalità di definizione del context a partire dall’attributo. In particolare a tal riguardo è possibile definire context a partire dalla manipolazione di attributi semplici, ovvero tramite rapporto, somma o sottrazione di attributi, come mostrato in figura 3.4.4.
 
Figura 3.4.4 definizione context
Situation Manager Agent
Il frutto dell’operato ai passi precedenti trova compimento in questo agente, il quale sfrutta tutte le informazioni prima inserite, quindi i context attributes ed i context spaces, per la definizione di nuove situazioni. Come ci si aspetterebbe dalla Context Space Theory, ogni situazione può essere vista come l’associazione agli attributi definiti in un context space, di una funzione di contribuzione e di un peso per ognuno. L’interfaccia tramite la quale avviene la specifica ed il caricamento da parte dell’utente di questi parametri viene invocata dall’Interface Agent, previa interazione in tal senso dell’utente, e generata dal Situation Interface Bean, come mostrato nella figura 3.4.5. La lista delle situazioni già presenti nel sistema è riportata nel riquadro più in alto, mentre selezionando dalla lista una delle situazioni già inserite è possibile consultarne il dettaglio nel riquadro in basso, dove ne verranno stampate le caratteristiche.
A questo punto si conclude la panoramica sulle funzionalità offerte nella prima fase di utilizzo del sistema, si presenteranno ora le modalità di fruizione della altre due, ovvero quelle relative all’acquisizione dei dati ed alla presentazione dei risultati elaborati. 
Sensor Data Manager
Si è già parlato più volte del ruolo svolto da questo agente; all’atto pratico, questo interagisce con l’utente direttamente solo durante l’acquisizione dei dati relativi ad i sensori virtuali. In figura 3.4.6 se ne presenta l’interfaccia. Qui vengono inseriti e caricati i valori dei context che verranno poi immagazzinati nel database in base alla data e all’ora di inserimento. Proprio in base a questa informazione verranno poi discriminati una volta presentati all’utente al momento di richiamare gli output da visualizzare.
Reasoner Agent
Il reasoner agent risponde alle richieste dell’utente di consultazione dei risultati delle elaborazioni circa i context state disponibili. Ancora una volta è l’Interface Bean che si occupa di fare da tramite fra i due livelli dell’applicazione, in particolar modo ciò avviene mediante l’Output Bean. 
All’utente viene quindi innanzitutto chiesto di selezionare una situazione fra quelle disponibili, ed in secondo luogo gli vengono offerti i context state disponibili e sui quali è possibile effettuare l’analisi. Al fine di aiutare l’utente ad analizzare al meglio la situazione per lui di interesse, egli può fornire al sistema una soglia di allerta che verrà utilizzata nella presentazione dei risultati per evidenziare innanzitutto il livello di soglia di tutta la situazione ed, inoltre, anche i singoli context che presentano valori di contribuzione superiori a quella soglia e che quindi sono potenzialmente i principali responsabili per l’innalzamento dell’alert. 
 
Capitolo 4
Conclusioni e Sviluppi Futuri
4.1 Validazione
Per testare l’effettivo funzionamento dell’applicativo sviluppato, sono stati considerati diversi lavori di SA realizzati nell’ambito di corsi di DSS, ed effettivamente il prototipo realizzato riesce ad essere di utilità nella stragrande maggioranza dei casi. In particolare nel presente elaborato viene descritto uno di essi che riguarda uno studio reale di situation awareness basato sulla context space theory con l’obiettivo di verificare la validità del sistema come alternativa agli strumenti usati in precedenza.
Lo studio scelto come riferimento analizza i fattori che possono minare la qualità dei prodotti di quarta gamma, ovvero quei prodotti alimentari comunemente definiti come “insalata in busta”. Il processo di produzione dei prodotti di quarta gamma prevede le seguenti fasi: selezione delle materie prime (ovvero i vegetali), pulitura, taglio, un secondo lavaggio con successiva asciugatura ed infine il confezionamento.
Gli attributi identificati come rilevanti ai fini preposti sono i seguenti:
	Orario raccolta materie prime 
	Orario lavorazione materie prime
	Adeguato trasporto campo – azienda
	Temperatura ambiente di lavorazione
	Data acquisto materiale per imballaggio 
	Data utilizzo materiale per imballaggio
	Temperatura di conservazione materie prime
	Numero di lavaggi 
	Temperatura dell’acqua
	Asciugatura adeguata
	Dipendenti senza attrezzature igieniche

Da questi attributi sono stati poi ricavati i context attribute, come presentato nella tabella a seguire; come si può notare, alcuni attributi sono stati utilizzati direttamente come context attribute, mentre altri sono stati ottenuti come combinazione elementare di attributi:
Attributo	Context – attribute
Orario raccolta materie prime
Orario lavorazione materie prime	Orario lavorazione – orario raccolta materie prime in ore
Adeguato trasporto campo – azienda	Trasporto adeguato
Temperatura di conservazione m.p.	Temperatura di conservazione m.p.
Temperatura ambiente di lavorazione	Temperatura ambiente di lavorazione
Numero lavaggi
Temperatura acqua	Qualità del lavaggio
Asciugatura adeguata	Asciugatura adeguata
Dipendenti senza attrezzature igieniche	Dipendenti senza attrezzature igieniche
Data acquisto materiale per imballaggio
Data utilizzo materiale per imballaggio	Permanenza materiale per imballaggio in magazzino in giorni

 
Figura 4.1.1 Contribution Function
Le funzioni di contribuzione, di tipo gradino, per ogni context attribute coinvolto nella situazione di interesse sono riportate in figura 4.1.1, mentre i pesi sono presentati nella tabella a seguire:
Context attribute	Peso
Orario lavorazione – orario raccolta m.p. in ore	0.2
Trasporto adeguato	0.05
Temperatura di conservazione m.p.	0.2
Temperatura ambiente di lavorazione	0.1
Qualità del lavaggio 	0.3
Asciugatura adeguata	0.07
Dipendenti senza attrezzature igieniche	0.06
Permanenza materiale per imballaggio in magazzino in giorni	0.02

	I context attribute sopra descritti per la situazione in esame, ai fini della configurazione del sistema sviluppato, sono stati considerati come virtuali, quindi durante la fase esecutiva, i dati riguardanti le occorrenze sono stati richiesti direttamente all’utente tramite l’interfaccia mostrata in figura 3.4.6 del precedente capitolo.   Per quanto riguarda l’attributo “Qualità del lavaggio”, questo è stato caricato sostituendo al valore linguistico un valore numerico, concordemente a quanto riportato dalla sua funzione di contribuzione.
A questo punto, nello studio in questione, i dati riguardanti le occorrenze dei singoli attributi venivano elaborati mediante l’utilizzo di un foglio di calcolo excel ed il risultato dell’analisi della situazione era presentato all’utente mediante un cruscotto, all’interno del quale la lancetta poteva posizionarsi su una zona verde, nel caso in cui la situazione non avesse superato la soglia di allarme prefissata, o su una zona rossa in caso contrario. Per quanto riguarda la rappresentazione dei dati da parte dell’applicativo qui presentato, invece, ne è disponibile un esempio nella figura 4.1.2 (i dati utilizzati sono forniti nella tabella sottostante), nella quale è possibile constatare praticamente quanto detto in chiusura del capitolo precedente circa la struttura della maschera di presentazione dei risultati. 
È stata verificata la perfetta aderenza dei risultati forniti dal sistema in esame con quelli riportati dallo studio preso come esempio. Questo, in aggiunta al fatto che il sistema è riuscito a supportare la corretta configurazione dell’ambiente di Situation Awareness utilizzato nello studio sulla qualità dei prodotti di quarta gamma, sancisce il successo dell’impresa che ha dato origine a questo lavoro di tesi.   




Figura 4.1.2 Output
Unità	Orario lavorazione m.p. – orario raccolta m.p. in ore 	Trasporto adeguato	Temperatura di conservazione
m.p.	Temperatura ambiente di lavorazione	Qualità del lavaggio	Asciugatura
adeguata
1	6	Si 	10°	18°	Scarsa	No
Unità	Dipendenti senza attrezzature
Igieniche	Permanenza materiale per imballaggio in magazzino in giorni
1	1	31

4.2 Considerazioni
La Context Space Theory, seppure apparentemente un approccio decisamente semplice ed intuitivo, si è dimostrata un valido strumento per l’estrapolazione da dati grezzi derivanti da sensori fisici o virtuali, di informazioni di più alto livello. Il prerequisito per la sua messa in opera è la conoscenza, più o meno approfondita, del dominio specifico di applicazione. In questa trattazione si è voluto separare la parte applicativa dal sottostante modello teorico al fine di sviluppare un mezzo pratico di ampio impiego per fornire un accesso diretto e rapido alla suddetta tecnica di Situation Awareness. Il risultato è stato raggiunto e lascia adito a future estensioni. Il prototipo sviluppato può prestarsi a diversi panorami applicativi, non essendo sottoposto a vincoli di sorta sulla qualità e la tipologia dei dati su cui operare. Si può dire quindi che il lavoro svolto ha rispettato le aspettative iniziali, l’obiettivo prefissato ed introdotto in apertura del presente lavoro di tesi era proprio quello di accorciare le distanze fra le possibilità offerte dalla situation awareness e tutti quegli ambienti in cui potrebbe portare beneficio la sua applicazione, ma che purtroppo ne sono privi a causa delle difficoltà e degli oneri legati allo studio ed all’implementazione delle sue tecniche. 
Per quanto riguarda l’architettura ad agenti, concretizzata grazie all’utilizzo del framework JIAC [14], si è rivelata adatta allo scopo prefissato, aderendo perfettamente agli obbiettivi posti dal punto di vista operativo, elencati in apertura del capitolo 3. Le difficoltà della sua applicazione si sono palesate soprattutto nella necessità di organizzare il lavoro di ogni agente in maniera tale che fosse il più indipendente possibile rispetto a quello degli altri, senza dimenticare la necessità di organizzare i compiti in maniera che questi potessero essere svolti in modo concorrente e senza rischio di incoerenze nei dati al livello più basso o di problemi di presentazione da parte dell’interfaccia. Sebbene si sia dimostrato, sotto alcuni aspetti, più difficile del previsto implementare il sistema mediante l’utilizzo di agenti piuttosto che altrimenti, rimane il fatto che questa scelta apre numerose possibilità per futuri sviluppi, sui quali alcune indicazioni verranno date nel paragrafo a seguire.
Il sistema ha raggiunto, al termine del suo primo ciclo di sviluppo, un numero soddisfacente di funzionalità, che potenzialmente già lo rendono adatto per applicazioni pratiche. Ne è un esempio la sua comprovata efficacia come rimpiazzo degli strumenti precedentemente utilizzati per svolgere le stesse mansioni, quali ad esempio Excel della suite di prodotti Office. I compiti di configurazione dei parametri necessari alla CST, di caricamento dei dati dai sensori virtuali e di presentazione delle elaborazioni vengono svolti in maniera robusta ed efficace. 

4.3 Sviluppi futuri

Naturale evoluzione dell’attuale approccio al problema nei confronti dell’interfacciamento del sistema con l’utente, può essere un’estensione web del livello di presentazione. Inoltre, visto l’utilizzo di un database come supporto per lo strato dei dati, un’ulteriore feature che il sistema potrà implementare sarà il supporto al multi utente, che in perfetta sinergia con la volontà prima manifestata di dotare il sistema di accessibilità mediante la rete, potrà aggiungere alle proprie caratteristiche quella di configurazione e fruizione dell’ambiente di SA da remoto. 
Per quanto riguarda l’estensione delle funzionalità già presenti, di sicuro un fattore chiave sarà la progettazione e l’implementazione di nuovi agenti per la raccolta dei dati dai sensori fisici, così come agenti specifici per il caricamento di nuovi tipi di contribution function. Nel primo caso, contestualmente alla realizzazione del nuovo agente, sarà necessario rivedere il sensor manager agent al fine di ampliare in funzionalità, coerentemente al tipo ed alle modalità delle rilevazione degli agenti in questione, il suo meccanismo di gestione dei dati. Mentre nel secondo caso, in merito al Reasoner Agent, questo dovrà essere esteso nelle sue capacità di gestione delle funzioni di contribuzione, per poter garantire completa compatibilità con il meccanismo di estrazione del contribution value. 
Nel dettaglio, al fine di poter dialogare anche con attributi linguistici, di sicuro vantaggio per tutta la struttura concettuale può rivelarsi l’aggiunta di un agente in grado di caricare funzioni di membership fuzzy e di supportare tale approccio alla SA. Questo perché tale tecnica si è rivelata all’atto pratico di utilizzo efficace ed efficiente, dunque decisamente diffusa nel panorama comune. 
Infine, al momento la presentazione degli output è unica e già descritta in chiusura del capitolo precedente, eppure spesso la chiave nell’analisi di una situazione è proprio la modalità con cui i dati vengono rappresentati, vuoi per mezzo di cruscotti, diagrammi a barre, diagrammi a torta e quant’altro. Può essere di sicuro impatto positivo, dunque, fornire all’utente un significativo ventaglio di opzioni fra cui scegliere la modalità di rappresentazione delle elaborazioni sulle situazioni. Come conseguenza della suddivisione dei compiti fra agenti, quest’estensione richiede solo l’aggiornamento ed il potenziamento del Bean specifico presente nell’Interface Agent, dunque senza alcun bisogno di manipolazione nello strato della logica o dei dati.  
Nel livello più basso del diagramma architetturale a livelli troviamo la raffigurazione della base di dati, proprio in questo livello, nell’ottica dei futuri sviluppi, dovranno avvenire parte degli aggiornamenti necessari per il supporto di utenti multipli, a cui prima si faceva riferimento. Qui si riflettono, naturalmente, anche le conseguenze dell’aggiunta di nuovi agenti, vista la necessità di dotare il database di strutture apposite per l’immagazzinamento dei riferimenti a questi nuovi tipi di attributi. Simili aggiornamenti saranno necessari anche per il supporto alle nuove tipologie di contribution function, la progettazione delle entità e delle relazioni dedicate proprio a queste funzioni dovrà avvenire in maniera coerente alle strutture già esistenti e rispettare il modello utilizzato nella generalizzazione dell’astrazione teorica. 
 
Bibliografia
	Juan Yea,*, Simon Dobsona, Susan McKeeverb, Situation identification techniques in pervasive computing: A review,  Pervasive and Mobile Computing 8 (2012) 36–66
	S.W. Loke, Incremental awareness and compositionality: a design philosophy for context-aware pervasive systems, Pervasive and Mobile Computing 6 (2) (2010) 239–253.
	D.J. Cook, J.C. Augusto, V.R. Jakkula, Ambient intelligence: technologies, applications, and opportunities, Pervasive and Mobile Computing 5 (4) (2009), 277–298.
	L. Chen, C. Nugent, M. Mulvenna, D. Finlay, X. Hong, Semantic smart homes: towards knowledge rich assisted living environments, Intelligent Patient Management 189 (2009) 279–296.
	C. Bettini, O. Brdiczka, K. Henricksen, J. Indulska, D. Nicklas, A. Ranganathan, D. Riboni, A survey of context modelling and reasoning techniques, Pervasive and Mobile Computing 6 (2) (2010) 161–180.
	L.R. Rabiner, A tutorial on hidden markov models and selected applications in speech recognition, Readings in Speech Recognition (1990) 267–296.
	D.L. Vail, M.M. Veloso, J.D. Lafferty, Conditional random fields for activity recognition, in: AAMAS’07: Proceedings of the 6th International Joint Conference on Autonomous Agents and Multiagent Systems, ACM, New York, NY, USA, 2007, pp. 1–8.
	D. Moore, I. Essa, Recognizing multitasked activities from video using stochastic context-free grammar, in: Eighteenth national conference on Artificial intelligence, American Association for Artificial Intelligence, Menlo Park, CA, USA, 2002, pp. 770–776.
	D. Rios, Neural networks: a requirement for intelligent systems, 2007. http://www.learnartificialneuralnetworks.com/.
	Multi Agent Systems, M. Wooldridge 2002
	Searle, 1969
	O’Brien and Nicol, 1998
	The FIPA-OS Agent Standard: Open Source for Open Standard, Posland 
	JIAC TNG Developer Documentation, dai-labor, www.jiac.de


